from scraper.rss_fetcher import RSSFetcher
from processor.summarizer import Summarizer
from storage.graph_interface import GraphStorage
from storage.db_interface import MongoStorage
from datetime import datetime

from connectors.llm import DeepSeekClient
from storage.vector_store import VectorStore


def update_knowledge_base():
    """
    Ingests and updates the agent's marketing knowledge base.

    This function:
    - Fetches new marketing-related articles from RSS feeds.
    - Summarizes the content using a local or LLM summarizer.
    - Persists the processed articles in:
        - MongoDB (raw and summarized data)
        - Neo4j (triplet-based graph knowledge)
        - FAISS vector store (OpenAI embeddings for semantic search)

    It should be scheduled to run daily or at regular intervals as part of a
    long-running knowledge agent.

    Side effects:
    - Writes to MongoDB, Neo4j, and vector index on disk.
    - Prints log-style status messages to stdout.

    Returns:
        None
    """
    print(f"ðŸš€ Starting Marketing Agent - {datetime.now().isoformat()}")

    fetcher = RSSFetcher()
    articles = fetcher.fetch()
    print(f"âœ… Fetched {len(articles)} relevant articles.")

    if not articles:
        print("âš ï¸ No relevant articles found. Exiting.")
        return

    summarizer = Summarizer()
    db = MongoStorage()
    graph = GraphStorage()
    vs = VectorStore()

    processed_articles = []
    for article in articles:
        article["summary_processed"] = summarizer.summarize(
            article["summary"] or article["title"]
        )
        processed_articles.append(article)

        # Store in MongoDB
        db.save_article(article)

        # Store in Neo4j
        graph.store_article(article)

    # Store in Vector Store
    vs.add_documents(processed_articles)

    print(f"\nâœ… Completed at {datetime.now().isoformat()}")


def query_knowledge_base(query: str) -> str:
    """
    Queries the agent's knowledge base using a natural language question.

    This function:
    - Performs a semantic search over the vector store using the given query.
    - Retrieves the most relevant marketing article summaries.
    - Sends the result to an LLM client to generate a professional summary.

    Args:
        query (str): The userâ€™s natural language question (e.g., "What are the latest SEO trends?").

    Returns:
        str: A synthesized and fluent answer generated by the LLM based on retrieved knowledge.
    """
    vs = VectorStore()
    results = vs.search(query)

    task_description = f"""
    TASK: Summarize the following information in a professionally sound manner.

    {results}
    """

    llm_client = DeepSeekClient()
    summary = llm_client.summarize(
        agent_description="You are a marketing expert.",
        task_description=task_description,
    )
    return summary
